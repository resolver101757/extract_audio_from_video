You have a few different conferences, but we had one, and one of the keynotes was a person from Microsoft, and he was showing all the new pilots, like up-and-coming stuff, like stuff for 365. There's just like a million of them, but there was one where it does something like that where it'll summarize meetings for you. Yeah, yeah, it's great, isn't it? It'll take all the text or whatever and give you all the high-level key points and kind of build out your action items and all kinds of stuff. I hope that helps reduce the amount of meetings you have working for a normal job. It's like, oh, let's set up a meeting for this, oh, let's do another one, and it's like, yeah, just send me the memo where the content is fine. Sometimes there might be some kind of push-pull. You're just kind of reducing everything to PowerPoint. Yeah, yeah. People will be like, well, stop attending meetings, and just one person speaks or something. You can see where it's all going, though, can't you? Because if you can record all these conversations, and then you've got all the other stuff that go, you sort of summarize all that conversation. Then you've got another meeting happening somewhere else in the organization. You sort of summarize all those, and then you summarize all the summaries.gets filtered up to the execs and they can sort of get an idea about what's happening in the organization. I watched the Lex Friedman interview with Jeff Bezos. He kind of turns it around. What he was saying is PowerPoint is easier on the presenter and harder on the audience. But what they do is the presenter writes a 6 page memo, and then they go to the meeting and everyone reads it. It's like doing everything in reverse, you know, and then summarizing it afterwards. You put your key points first and then discuss. I also had a colleague who worked for Amazon for like half a year and then he came back. So we could talk about how it's like working there. All these things that you hear, like the memos, the 2 page... Yeah, write down your thoughts or proposals instead of trying to convince somebody with nice PowerPoint slides and stuff. It's all true, they really do it. It's a bit more effort to do. Of course, it's easier to just jump into a meeting and just start talking. But he also said it really helps. So it's a positive thing if you've got a really, really huge organization. Of course, if you've got a small team, it doesn't make much sense, but yeah, it's really interesting. It keeps people from asking questions that you're going to answer on the next slide or whatever. They read it or whatever and ask questions. Have you ever heard of Edward Tufte?the score see whether that improves the results and I've just been building up the tool set I needed to capture the data and I've hit a few problems with capturing the data from images so because I've got multiple screens set up at work and it's just trying to work out which screen you're capturing the information from and making sure everything's picking up the right coordinates from the right screens so yeah that's what I've been looking at and I'm hoping because the other guy who's working on it was also one on this sort of a discord group he's been getting that accuracy of about 1% or less than 1% and I'm getting nowhere near that at the moment so I've got to capture a few more images and also just make sure that everything's working in the pipeline that I've got so it's quite a fun project there's something else that I've gone through I don't know if anyone else has got anything that want to go through because this isn't sort of important but I just wanted to throw out in case someone's got some thoughts I'm trying to work out what projects to do next and it seems to me that like transfer learning is a big thing at the moment and fine-tuning and there's a lot of data sets out there and I came across one called tiny llama which is the same architecture as llama but it's just 1 billion parameters so it's big enough to go on a phone and there was someone who did a sort of fine-tuning on of it and I thoughtI want to do something similar, but I'm just trying to find some data that would be good for it. I can present what the project is and what they've done, and then if anyone's got any suggestions for me, yeah, happy to sort of to hear it. But if anyone else has got anything that they really wanna ask and sort of work on at the moment, then they can do that, because it's not super important, but then if no one's got anything, then I can show this. Okay, cool, entire screen, I need to click the screen, that's why it's not showing. Okay, cool, so I'll show this. So this is the GitHub page of it. So it's TinyLimer, it's getting loads of commits. So 1.1 billion parameters, I haven't worked out what size that is, do you know, for inference, but I imagine it's only probably a few hundred megabytes, maybe, I don't know, so I'll have to work that out. I can actually click on one of these, can't we? And it'll tell us roughly. So this is the model, one of the models, and it's 4.5 megabytes.It's a 4GB model, so you'll be able to run it on your phone easily enough. There's some way you can actually test it, so you can write in here, I don't know, I thought this was quite interesting. So, it can tell you how to break into a car. Yeah, yeah, but it's reasonably accurate as well. There's no safety on this one? No, no, no, because what they're saying is because it's so small you can't actually... Are you going to ask how to kill myself or something? Yeah, I don't want to send the alarm bells off, I'll probably have someone come and visit me. Yeah, yeah, yeah, it's fine, I'm not anything like that, but yeah. Yeah, so it's quite coherent as well for such a small model and it just surprised me how good these models are. I don't know if anyone else has been looking into this area, but it's fascinating to me. Last night they were presented at Cluster of Stars.they presented a paper on tiny stories. Yeah, yeah, yeah, that one, yeah. And basically, the data comes from GTT4, and they write prompts to create simple paragraph-long stories at the level of a three- or four-year-old. And then they used all that data to train a model. And I think the models are, I don't know if they're like alien grammars or something. Some of the results were grammatical. Sometimes it didn't get the reasoning quite right, but it's still decent. Yeah, it kind of made sense. They had GTT actually evaluate it as well, and it was, I think they gave it scores of creativity, grammar. There was something else, but it was scoring like a seven, maybe, at a 10 to 12-year-old level. I think the training process for small models is a lot easier than for the... So once the state-of-the-art model like GTT4 comes out, they've done all the heavy lifting. They've done all the training, and what's also really expensive is the reinforcement learning by human feedback. And basically, once this model is finished, you can train your own fake GTT, basically, and leave out the reinforcement learning by human feedback by just using GTT4 as a human. And then basically, it gets a lot easier to scale.to make a new model. Of course, it's not as good as the GPT-4 or whatever, but it gets easier once something like that is out there. Yeah, and it's also... You go for it. Go ahead. No, go for it. No, no, you go for it. I'm interested in what... It's just like something that's kind of like, no duh, you have a higher quality data set. But then they're also talking about... I don't know if anyone has done this, but use high quality, non-synthetic source. I don't know if it's called small Wikipedia or tiny Wikipedia or something. That would be an interesting project to see how it compares to a synthetic data set. Yeah, well, it's kind of the thing that I'm thinking about. What I want to do is something within my industry. Whether there's an open data set that would be useful to train a small model. Because the advantage of a small model, it can fit on an edge device. Like in the industry, you might have a PLC or a Raspberry Pi or something like that, controlling something, and you need a fast response. You don't want to send it up to the internet because you might not have an internet connection where you are or whatever. So that might be a good use case of this type of model. Or you just want something that's cheaper than GPT-4. You want something that just runs constantly and it's not going to break the bank. But it's very good at a very specific job.So it's either finding the data that is already there in my company or elsewhere on the internet or just getting GPT-4 just to create something that's roughly what I want for my target problem. I just can't figure out what the target problem is yet. I'm just exploring what the sort of use cases of these tiny models are, where they're good, where they're not good. I wonder if something like Wikipedia or whatever it's called, the tiny Wikipedia is a good way to go because then you don't have to pay GPT for it. You could train it on Wikipedia as a base and then find a dataset within your company and clean that up and then fine-tune that model. Yeah, I don't think it's going to cost that much from GPT-4. Maybe I'll do some sums and to come back to you next week. But for this dataset they're using, all they're doing is training it to, when someone types in the description, it just gives back the colour in hex. So if someone types in, I don't know, I want a red colour with a slight dark shade of whatever, it'll try and find out which is the closest one.And that's what the language model is essentially doing. It's trying to summarize into a hex. But there are only 33,000 rows. So we did 33,000 API requests. And why is the cost of GPT-4? Do you have a GPT-4 account or paid account? Yeah, I've got one for my personal but I could just create one through work, just use Azure. Okay. And then it just... It could be a little more cost effective to use like 3.5. Yeah, yeah. Yeah, good point. Yeah. But that looks like for 1,000 tokens, 1 pence or $1. So it would be 33,000. So what's that? 33 pounds. So about $30. I don't know. I don't know. Everyone's got different comments here, but yeah, it's not going to be a huge amount. So yeah, if I've got some way of generating that, I could do that way. So I don't think it would be that hard to generate this through GPT-4 API. Let's go back to this one.Felly, mewn hyn, maen nhw wedi cael sgript sylweddol sydd wedi cael ei wneud, felly maen nhw'n gwneud yr holl beth, mae'n eisoes wedi'i gwrthi i chi, ac maen nhw'n defnyddio Laura, sy dwi ddim wedi defnyddio, ond rydw i wedi clywed rhywun yma i siarad amdanyn nhw. Felly, mae fy nghyfarfod yw, mae'n rhoi nifer o ffyrdd i'r gweithle neurol y gallwch chi hyfforddi, felly mae'n rhoi'r holl ffyrdd eraill, mae'r holl ffyrdd eraill, mae'r neuronau eraill yn ffros, ac yna maen nhw'n ddifrifo'n ffordd ychydig o ddŵr cyn i mi ddarllen eich cyflwyniad. Felly, dywedwch i mi os ydw i'n iawn yma, ac yna byddwch chi'n drosglwyddo'ch holl ddata a dwi'n meddwl am y rhwystrau dysgu, dydych chi ddim eisiau i'r rhwystrau dysgu fod yn cyhoeddiol fel yr oedd o'r blaen, felly dydych chi eisiau iddyn nhw fod yn ffyrdd fawr iawn, ac felly mae'n ddifrifo'n ffordd ychydig o ddŵr cyn i mi ddarllen eich cyflwyniad eraill, o'r ddŵr, o'r ffwrdd diwethaf, a bydd hynny'n rhoi canlyniadau i chi. Diolach hellyr. ac os feddwch wrth i mi ddarllen i gyd band Lu21524, rydw i'n meddwl ei fod wedi drwy plwyfod, dyma'r cyme Music CD a dda i ddangos am yr holl ffordd dan elwen, felly dyma'r cnymidd fi. Rydw i'n meddwl i amddangos nodau bobl arnoch, rydw i'n meddwl i chi wastad mewn rhan holla i gael eu hadrodd.blue colour and that's the response it gets back which is just the hex decimal number of the colour he wants and then he times it so it's 2 seconds to get that back. I don't know what device he's using but still 2 seconds isn't a bad response time. Like I say I've not gone through all this code. I know we talked about GPT-4 and I don't know where else to find these other datasets other than Hugging Face. If anyone's got any thoughts on that as well I might do some research on that area and see whether there's anything else that's useful that I can include in the project. So that's it. I'll post those links in the chat window so people can follow it and I'll probably follow it up with next week or the week after with any sort of results that I've got or anything if I decide to move it forward but this is the sort of idea that I've got. I just think it'll just be a good project just to understand how you can use these smaller models but ideally I want to get one on a phone just to see how it would run.Have you looked at, I haven't looked at this for a while or dug into it too much, but the UCI Irvine Machine Learning Repository? No, no. What was that? So UCI? Yeah, I'll share it. This has been around for a while. I don't know if they, I thought I saw someone using like text messaging data from it. That was, that was kind of fun. I think they have the same one we see here as a chat. There's Hockey Face obviously, but this might be another place to look. Oh, for the datasets. Yeah. Okay, I'll take a look at that one. Thanks. Sounds good. Yeah, if anyone else has got a project they're working on, yeah, speak up. Can you explain how do you do memorization of the meeting? All right. Yeah. So I've got this, I'm still sharing my screen, aren't I? Can you hear me? Yeah, I can hear you. Yes. I was saying, the question is, how do you do this?All right, so I'm using this here to capture Okay, just let me switch to my mobile Just two seconds So yeah You YouSilence. Silence. Silence. Silence. Fucking piece of shit. Silence.It takes input as state and the year and month and gives the value. So it is presented like a graph for any state. I can get the predicted values. And again for historical data we can analyze to know what was happened in which year like to know the trends. How the values of year quality got changed over the years. And also like these quick facts again. Select the range from this. Cleanest month always comes first. Worst month is December, most polluted year. And also this feature of comparing the cities for their monthly averages. I can select any number of cities and this is the average graph for every month. These are the southern cities of our nation. There are some red lines and the north region has some cities which are having the highest in May, March or in December.like there are 5 levels if i plot the graph for air quality between 0 to 50 it is acceptable and above 300 it is really hazardous like if i plot the eq i have so i can see just a second i see okay like it is for like CO concentration like it will give so like these are to see so the black ones are just above 300 so these are hazardous values and green ones are okay like you can have below 120 so these are the levels so like it is 0 to 500 scale only and above 300 it is harmful and so here i can compare the cities for their average monthly trends and again this is like for all the cities for all the years like some states like this kerala had less than 150 till 2012 then something happened that they changed their values to 200 so these things can be analysed and every state has its own story to figure out and like Delhi getting the highest values near 400-500. I can remember being in Delhi and it was all the haze from the smog from the pollution from the factories it was absolutely nuts.But the best feature of our app is its impact on external factors. So what they said in Hackathon was to utilize their Snowflake marketplace databases also. So I took the both databases and compared it. If I took the respiratory problems data set and compared it for Delhi, for monthly averages, graphs were matching so clearly. And I can calculate the correlation score. Like it is 0.5. And these are the states which are having the correlation score higher. And I can also compare it by yearly average also. This is also the best match, like 0.7 correlation. And these many states are affected for respiratory problems with AQI values. As AQI values are dropping this year, so the respiratory problems also dropped. And there were also other data sets which I combined with them, like the vehicle registrations, like new vehicle purchases. And so these were the states which showed higher correlations. Like if I compare for Tamil Nadu, then it will show higher correlation, like this. And for monthly average also, I can compare them to get this kind of graphs. And correlations score, like so many states, are related for new vehicle purchases and their AQI values. So this can be a really good match.nice insight also like energy demands data set was also compared so I utilized this also and these were the states which were correlating so they found these insights really helpful and that's why like also compared at the nation for country level all over the India if I compare coal production and I take this one month so this is like very shocking like these were the values which are taken from different areas and such a large scale there so also like I compared it with life expectancy of the nation and it showed correlation of minus 0.6 which means like if AQI values are rising then life expectancy will surely decrease. So this was it and yeah I got the first prize for that also. Also I presented it to 1200 developers during the event of Snowflake and also got the first prize for that as well. What was the prize you won? Yeah, this was iPhone 15. Alright, awesome. Yes, it's like a couple of, I don't know how many rupees is that, it's about a thousand pounds.good price and also like it took for me to wait just one week to build all this like the hackathon was going on since two months but i saw it like 10 days before and start working on it so i've got like one question um like what did you use for building this website because it looks like streamlit and i've seen it like really a lot and i think it's like i could you like explain like how how hard it is and like how easy it is like what's your approach with streamlet basically yeah you're creating like apps with streamlet like it is really very easy as compared to if you use any other tool to build websites yeah so like it's very easy and like python based so the language is also easy but it gives you like a simple kind of theme so i just put custom css and html in it to get these themes like a normal streamlet app does not give you these kind of graphics but yeah that looks are just nice if you use the default one also so very easy like also deploying it on cloud is also really easy i see so you can basically because it's like python based you can um embed all the kind of graphs and heat maps that you've had you can just natively embed those in the website basically yeah these kind of graphs like i created with plotly so you can create with streamlet also but there's more functionality so not very hard like for if you want to create thisa single page of SpringBlade, you will just write st.title and give your text and it will create the first page of your app. And it's simply very easy for creating these kind of pages. Nice. It's a serial done as well. That's really cool. I think I'm going to play it. And so when you're writing a code, you write each element. So the title, the subtitle is your city, and then the text will be another, the next line of code. So I can tell you, I wrote st.title, then st.subtitle, then st.text, then I write st.column. And for column one, I wrote this st.subtitle, st.inputText and give the list of values. You just have to give values in functions and it will give you just an input kind of thing. And this is also the SpringBlade component, like st.metric and give these kind of values in a list and it will present like this. In other column, you can plot the graphs. These are components. You'll be able to get something up in about five, 10 minutes. Just a very simple page. It's that easy. Yeah, very easy. If you know the functions, you can simply write them. I've created a Streetlight app and it was pretty straightforward. We use, you mentioned Snowflake, too. We use Snowflake at work and I think they have integration or they work together. So like Snowflake, you can getThere's all kinds of open data sets available So that would make it nice to you have streamlined to make your web app and then and then You could use snowflake as a database and plus it has all these public data sets you can use Yes, so this was the data set I used It has title lots of categories. Then I searched for those which were important for me Was that in the marketplace that the idea? Okay. Yeah These two were market place like economic monitor and social impact and this I created for me like historical data and So snowflakes got its own sort of ecosystem for data Snowflake and I went to some of their conferences and they're trying to like take over the world They've got like notebooks. You could do like machine learning like they're I think they're trying to link just do everything Databricks or is it coming from a different approach? Yeah, I'm trying to we also use data bricks I'm trying to compare like maybe yeah, I think maybe it's possible and so It's our competitor Because they have machine learning notebooks they have you know stuff that's more You can do ML. That's you know Kind of like easier to do but then youyou can also like, you can create, yeah, like, Kubernetes, I always say this wrong. You can make your own containers. I have to look it up on how to pronounce it again, but you know what I'm talking about. But, yeah. And then they obviously have all the data. What's that? Kubernetes. Kubernetes, there you go. Yeah. I don't say that for a while, like I forget how to pronounce that. One of the most hyped concepts in recent years. Heard a lot of times. Okay, that was really interesting. Thanks for sharing. Congrats on the first prize. Yeah, thank you so much. Congratulations. I could share like, what I'm planning to work on from now on. It's like, really quick. Because I didn't really start so much. Go ahead. No, I've actually put that on ice for now. But I found something more interesting. Let me see. Mamba, is it? Mamba. So I think you should see my browser. Can you see something? Yeah, it's up.Okay, so I've got a lot of time right now because the semester starts in April and I just have a small working student job, so I'm free to work on whatever project I want to. And I thought, well, maybe I should try something more challenging, and if you know TinyGrad, it's like a pretty new, yeah, well, PyTorch replacement, I guess. It's like a new implementation of all these basics and they try to make it more efficient, make it simpler. And, yeah, they've got, like, yeah, a lot of people are trying to get... The guy who runs it is quite interesting, isn't he? He's very sort of out there. Yeah, yeah, short shorts. The cool thing about it is, like, it's an open source project, which is, like, in its earlier stages, so I feel like, compared to PyTorch, there's a lot more room to contribute, basically. That's what I'm trying to do. You've got, like, the TinyGrad bounties. I was trying to, maybe my knowledge is enough, maybe I could do something here, and it's like... I'm not sure where I can find the list, but it's like an Excel sheet. Oh, yeah, it's here. So you just open this, and I just went down and looked which of these I could do, and it's like a lot of these are, like...Yeah, I don't know what the fuck it is Five deep flop and explode gem on yeah But I was I just picked out one of these here, which is training the unit 3d It's like an issue and a couple of people have already tried But they failed because they I don't know they had like different problems and that's like what I'm trying to work on right now So I've got like I started out with a bit of code and it's like I've got the the data set pre-processing and all that that's already working and Also, what's really cool is I already have my leg first contribution Super small There was like kind of a bug with a move command there Which is like an arrow so I just made a pull request. It's literally just one line, but it's merged So I've got like a little bit of success Every step counts So the goal is to like I don't know it's probably gonna take a lot a lot more time and I've got a Lot of things and maybe I was not able to do it because it's basically training the entire unit which takes a lot of compute So I'm gonna have to find a way to do that. But in the case I would succeed I would get like $500 something so I'm trying That's what all those like dollar amounts are in the spreadsheet, where's the spreadsheet? Yeah, yeah, that's like the bounty price that you get is that link to on the other github pageSo this is the overview Excel sheet, and then you've got pull requests for issues. For the unit, there's also a GitHub issue. But there's really not a lot more detail in there. You've got to join the Discord to get more details. Okay, I see. So yeah, that's really not a lot of information. But how did you find this Google Doc? I just went to their website, and then I found their bounties, and then I found the link. Okay. So they link it there. Yeah. I watched a podcast. It was George Holtz on there, and he was talking about it. He was saying that you can get a job once you've done this. So once you've done a few bounties, or even one bounty, you can go off and get a job. I think, honestly, it's like once you can do one of these, once I complete training unit 3D, in case I succeed, I think the other ones are also really simple, because, of course, it's like different model architectures, but most of it is like getting familiar with the tiny Grad code base, and then integrating it there. I think once you finish one of those, I think you can easily just do the exact same process that you used for one of those for all the others, and then you can get all the bounties. So I'm not fully understanding what is required for that. What skill sets do you need to know to actually do that bit that you're talking about now? So in this case, it's training a unit. So the unit 3D, they've got like benchmarks.They're linked here. So they specify the data set and the training rules, which is based on this ML performance benchmark. And based on this benchmark, you've got to write some implementation. So a few of these things are implemented, like the model architectures are implemented. A few of the data set download, preprocessing strategies are implemented. Like the training logic of which optimizer to use, which hyperparameter set, and all of that. A lot of it is specified, but the code is not there. So first of all, you've got to implement the code for the training logic. And then you've also got to run the training process. And is it writing it in CUDA, or is it higher level than that? I don't quite get what the sort of, because this is a replacement for, say, PyTorch, isn't it, or a competitive PyTorch. I'm not understanding how low level you've got to get with this. So yeah, I think a lot of it is Python. So in this case, this issue, you just broke the Python class again. It was already existing architecture of TinyGrid that's already in there. But I've seen that, so to get into the exact TinyGrid tech stack, there's also some documentation, which I probably still should read. But for this issue, it's mostly Python. But if you want to work on other places on the code, I've seen there's calls to some C code and stuff. So I think it goes. So they've written.They've written up the API for TinyGrad in C or whatever language, and then you've just got to interface to their APIs to generate this model. Yes, I've got, of course, the Python interface, so if you're just a normal person using TinyGrad, you can program everything in Python, but I've seen there are some C interfaces, which I didn't really look into, but for this issue, it's just Python. Are you going to spend $500 on compute to fix the bug? I'm not sure how much you have to spend, like, I'm willing to pay $50 or something, but yeah, that's a good point, of course, if it's too expensive, yeah. Yeah, maybe, yeah. The other thing that struck me, too, I was confused a little bit because I'm going through a neural network, so you're going to hear, like, TinyGrad, TinyGrad, no, it's MicroGran, so I'm building MicroGran right now. Yeah, yeah, yeah, it's a good idea. Kind of similar names, like FastAI Part 2, Mini, like RNN, or like Mini, whatever. What was the guy's name that you said created this, you said he's a character? It's GeorgeHot. GeorgeHot. He's got, like, a lot of interviews and stuff, and he's got, like, some crazy wide views. And it does live coding as well, it's quite interesting. It's very unique in its own way.perspective it's famous because he had the PlayStation back in 2010 or something it probably did that as well yeah yeah you can look into it it's like you don't have to agree with everything he says or so, but it's really interesting to watch a few of those, I really like it. but he seems to be on the same territory as trying to make AI affordable so he's got an AI driving company as well you know automated driving and he's trying to sort of get that off the ground and I think this kind of leads into that if you can get a more efficient AI language so writing tensors so processing tensors then that'll help his other sort of company which is all open source again I think yeah it's just an interesting way to take on how he's doing this and he's also got some hardware out there which is sowhich is like super fast, but cheap as well. Yeah, you can buy like a tiny software for this price, it's still expensive. I think it's like 50,000 euros or something. Let me see. But it's like got really good stats and it's like a good working machine. Yeah, I think it's a hound. Okay, empty your savings account. There you go, that's how you can train it. To get your 500 quid. You can get like a 500 quid discount on the tiny software. I was looking at the Lama computers a little bit. Okay, the base one is like $10,000. Yeah, but that's my plan, like working this week. And if it fails, okay, at least I tried. Yeah, I think you'll learn a lot from doing it, just even if it's just chatting with other people who are trying to fix it, seeing where their mistakes are. Yeah, it'll be interesting to see where you get with it, Max, and just let us know. Yes. That's really interesting to me, I might check that out. Okay, so, like any other product to share?nid ydyn ni'n gweld each un arna'r wythnos nesaf. Ie, dwi'n siŵr, dwi'n gwybod bod rhywun wedi siarad gyda fi'n gyntaf, ond mae fy nghyfrifiwr wedi dechrau gweithio yn y gysylltiad â'r antifyrwyr ac wedi penderfynu ei fod e ddim yn eisiau gweithio arall. Felly rydw i ar y ffôn, ond o ran y recordio, rydw i'n defnyddio, ond roeddwn i'n defnyddio, ond nid ydw i ar hyn o bryd, oherwydd nid yw'r mechanolion yn cysylltiedig. Roedd defnyddio obs i recordio ac yna rydw i wedi ysgrifennu sgript i'w rhoi i, beth yw, Whisper, ac yna rydw i'n cael sgript yn ôl, felly rydw i'n rhoi sgript yn ôl i Whisper, ac yna rydw i'n cael sgript yn ôl, ac yna o'r sgript hwnnw, rydw i'n ei rhoi i GBT4, dim ond i ysgrifennu. Rydw i'n meddwl y bydd yna gweithgareddau allan yno sy'n gallu eu gwneud yr holl beth. Felly dweud yn ôl. Dwi'n ddiolch, dwi ddim yn deall, dwi'n dweud yn ôl, dwi'n mynd i newid y folwm. Helo, helo, gallwch chi fyny? Ie, ie, gallwch chi fyny, ie, ie. Ie, roeddwn i'n meddwl os yw'n cyflwyno yn y ffynonell cyffredin, fel y sgript rydych chi'n ei rhoi i GBT4. Mae'n unig yw'r sgript, ie, ie, ie, felly rydw i'n cael y sgript yn ôl o'n Whisper, ac yna rydw i'n rhoi hwnnw i'r GPT4, ie. Felly, mae'n unig yw'r sgript yn ôl o'n Whisper, ac yna rydw i'n rhoi hwnnw i'r GPT4, ie.I wanted to know is the text short enough so that you can paste it into the chat window or give it through the API or is it like too long, what do we chunk it up basically? Ah right, okay, okay. It's been short enough for everything that I've needed so far. Yeah, it sounds like a straight forward way. I think it's also like cheaper than like all these online services that do the summary for you which then charge some ridiculous fee or basically a simple task. Yeah, I wanted to know how to pipe it all together as you know because that's what we're like, isn't it? We're all here to learn so I just thought as a learning exercise it took a bit longer than I wanted to. It took me about 45 minutes, maybe an hour just to get it whereas I could have signed up to one of those services and back then. But yeah, I just had a few problems because I did have to chunk the bits that I was sending to Whisper and it was just sort of troubleshooting that. Once I did that everything else was just straight. Yeah, well it sounds really useful. Nice, cool. I think we're going to meet next week again. Yeah, it was really nice meeting you guys today again. Yeah, it's always good. Catch you later guys. Okay, bye-bye. Bye, see you.Silence. Silence. Silence. Silence. Silence.